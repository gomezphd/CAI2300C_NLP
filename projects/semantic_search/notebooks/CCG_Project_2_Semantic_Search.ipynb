{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmPYPOIJ4FU5YhnV5qFnvT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomezphd/CAI2300C_NLP/blob/main/projects/semantic_search/notebooks/CCG_Project_2_Semantic_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project 2:** Semantic Search System for Customer Complaints and Legal Documents\n",
        "\n",
        "- **`Student`**: Carlos C Gomez\n",
        "- **`Instructor`**: Dr. Ernesto Lee\n",
        "- **`Date`**: January 29, 2025  \n",
        "---\n",
        "\n",
        "## 🔎 **Introduction to Semantic Search Systems**\n",
        "\n",
        "Semantic search represents an evolution in information retrieval, moving beyond simple keyword matching to understand the contextual meaning of search queries. This project implements a semantic search system with dual applications in customer service and legal document retrieval.\n",
        "\n",
        "### *Core Functionality* 🎯\n",
        "The system demonstrates two primary applications:\n",
        "1. **Customer Complaint Analysis**: Identification of similar customer issues for standardized response handling\n",
        "2. **Legal Document Retrieval**: Topic-based search of legal cases with semantic understanding\n",
        "\n",
        "### *Technical Architecture* 🛠️\n",
        "The implementation utilizes:\n",
        "- **Embedding Models**: OpenAI's semantic text representation\n",
        "- **Similarity Metrics**: Cosine-based relationship analysis\n",
        "- **Data Filtering**: Metadata-based refinement\n",
        "- **Interface**: Gradio framework implementation\n",
        "\n",
        "This implementation extends research by [Dr. Lee](https://drlee.io/building-a-semantic-search-engine-for-customer-complaints-with-openai-a61e9f4f2ba7).   on semantic search applications in customer service contexts.\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "ix1A60tmj8hK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📌 **Step 1: Dependencies**\n",
        "\n",
        "#### ***Sets up required Python packages***\n",
        "\n",
        "- **`OpenAI`** → Text embedding generation  \n",
        "- **`Gradio`** → Interface development  \n",
        "- **`SciPy`** → Vector similarity calculations  \n",
        "- **`NumPy`** → Numerical operations  \n",
        "\n"
      ],
      "metadata": {
        "id": "eWvkRENNaCum"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOYmywOlZ2qn",
        "outputId": "924be232-1451-4121-e8c8-df577acfb4a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install Required Libraries\n",
        "!pip install openai gradio scipy numpy -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 📌 **Step 2: Library Integration**\n",
        "\n",
        "#### ***Imports necessary components for system operation***\n",
        "\n",
        "- **`numpy`** → Handles numerical operations and array manipulation  \n",
        "- **`gradio`** → Creates the interactive web interface  \n",
        "- **`openai`** → Enables access to embedding models  \n",
        "- **`scipy.spatial`** → Provides distance calculations for similarity metrics  \n"
      ],
      "metadata": {
        "id": "UuvJtEd4aKpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "from scipy.spatial import distance\n"
      ],
      "metadata": {
        "id": "PacuDM-MaKd3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 📌 **Step 3: API Configuration**  \n",
        "\n",
        "The system requires OpenAI API authentication through **two possible implementation methods**.  \n",
        "\n",
        "---\n",
        "\n",
        "### ✅ **Method A: Secure Storage (Recommended)**  \n",
        "Colab Secrets provides a **secure** way to store your API key. Follow these steps:  \n",
        "\n",
        "1. **Open Colab Secrets**  \n",
        "   - Click the 📁 **folder icon** in the left sidebar  \n",
        "   - Select the 🔑 **key icon** (Secrets) at the bottom  \n",
        "   - Click **\"Add new secret\"**  \n",
        "\n",
        "2. **Enter Your API Key**  \n",
        "   - **Name**: Enter exactly `OPENAI_CAI2300C`  \n",
        "   - **Value**: Paste your OpenAI API key (starts with `\"sk-\"`)  \n",
        "   - Click **\"Add\"**  \n",
        "\n",
        "3. **Important**: The secret name **must** be `OPENAI_CAI2300C`, exactly as shown.  \n",
        "\n",
        "---\n",
        "\n",
        "### ⚠️ **Method B: Direct Implementation (Less Secure)**  \n",
        "* Alternatively, you can **hardcode** the API key directly in the script (see Method 2 in the code below).  \n",
        "\n",
        "* However, this method **exposes** your API key, making it **less secure**.  \n",
        "For better protection, **use Method A (Colab Secrets)** whenever possible.  \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uBTbaN0taKPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "#  ✅ **Method 1: Using Colab Secrets (Recommended)\n",
        "#------------------------------------\n",
        "\n",
        "# Import required libraries\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Retrieve API key from Colab Secrets\n",
        "openai_api_key = userdata.get('OPENAI_CAI2300C')  # Ensure correct secret name\n",
        "\n",
        "# Initialize OpenAI client if API key is successfully retrieved\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "    print(\"✅ OpenAI API Key loaded successfully from Colab Secrets!\")\n",
        "else:\n",
        "    print(\"❌ Failed to load API Key. Please check:\")\n",
        "    print(\"  1. You've added your API key to Colab Secrets with name 'OPENAI_CAI2300C'\")\n",
        "    print(\"  2. The secret is saved successfully\")\n",
        "    print(\"  3. Refresh the page if issues persist\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0kn6pPa1Ed6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7613bd5-d392-41c7-f0b9-825699545338"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OpenAI API Key loaded successfully from Colab Secrets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Method 2: Manual API Key Entry (Less Secure and need to comment out above cell)\n",
        "# ------------------------------------\n",
        "## from openai import OpenAI\n",
        "## client = OpenAI(api_key=\"your-api-key\")  # Replace with your actual OpenAI API key\n",
        "## print(\"✅ OpenAI API Key manually set!\")\n"
      ],
      "metadata": {
        "id": "CBL1jpC_m5H7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 📌 **Step 4: Embedding Function Implementation**\n",
        "\n",
        "The `create_embeddings` function serves as the **core transformation engine** for the semantic search system.\n",
        "\n",
        "### *Key Components*:\n",
        "- **Model Selection**: Utilizes OpenAI's `text-embedding-3-small` model\n",
        "- **Input Processing**: Accepts text arrays for batch processing\n",
        "- **Vector Generation**: Creates high-dimensional embeddings representing semantic meaning\n",
        "\n",
        "### *Technical Implementation Notes*:\n",
        "- Each text input is transformed into a *1,536-dimensional vector*\n",
        "- The process runs asynchronously for efficiency\n",
        "- Output vectors capture semantic relationships between texts\n",
        "---"
      ],
      "metadata": {
        "id": "1QCEG11AaJ0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Embedding Function\n",
        "def create_embeddings(texts, model=\"text-embedding-3-small\"):\n",
        "    \"\"\"\n",
        "    Create embeddings for a list of texts using OpenAI's API.\n",
        "\n",
        "    Args:\n",
        "        texts (list): List of text strings to embed.\n",
        "        model (str): OpenAI embedding model to use.\n",
        "\n",
        "    Returns:\n",
        "        list: List of embeddings.\n",
        "    \"\"\"\n",
        "    return [client.embeddings.create(input=text, model=model).data[0].embedding for text in texts]\n",
        "\n"
      ],
      "metadata": {
        "id": "i3zIBaw5aJqB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 📌 **Step 5: Customer Complaints Dataset**\n",
        "\n",
        "The system utilizes a **structured dataset** of common customer service scenarios.\n",
        "\n",
        "### *Dataset Characteristics*:\n",
        "- **Size**: 30 distinct complaint scenarios\n",
        "- **Coverage**: Multiple service aspects\n",
        "  - 📦 *Delivery issues*\n",
        "  - 💰 *Billing concerns*\n",
        "  - 🔧 *Product quality*\n",
        "  - 📞 *Customer service interactions*\n",
        "\n",
        "### *Implementation Purpose*:\n",
        "Provides a *robust foundation* for testing semantic matching capabilities across diverse customer service scenarios.\n",
        "---\n"
      ],
      "metadata": {
        "id": "h0HWguNJaJef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample customer complaints dataset\n",
        "customer_complaints = [\n",
        "    \"The delivery of my order was delayed by 3 days, and I had to constantly check the tracking system for updates. This caused inconvenience as it was a gift that I needed urgently.\",\n",
        "    \"I received a damaged product in the package, and the box itself was torn. It seems there was no care taken during the shipping process.\",\n",
        "    \"The refund process is incredibly slow. I submitted my request weeks ago and still haven't received any confirmation or updates on the status of my refund.\",\n",
        "    \"The customer service representative I spoke to was extremely rude and unhelpful, refusing to listen to my concerns or provide a proper resolution.\",\n",
        "    \"I never received the order I placed two weeks ago, even though the system marked it as delivered. I feel like my money has been wasted.\",\n",
        "    \"The packaging was torn and damaged when my order arrived, making it look like the contents could have been tampered with or mishandled during shipping.\",\n",
        "    \"The product I received doesn’t match the description on the website at all. It feels misleading, and I now have to go through the hassle of returning it.\",\n",
        "    \"The website is confusing and difficult to navigate, making it hard to find what I was looking for. The search feature also doesn’t provide accurate results.\",\n",
        "    \"I was incorrectly charged an extra amount for my order, and I can't figure out why. The customer support hasn't resolved this issue yet.\",\n",
        "    \"The warranty claim process is unclear, and I couldn’t find any detailed instructions on the website. I’ve been stuck without a resolution for weeks.\",\n",
        "    \"The size I ordered doesn’t fit, even though I followed the size chart on your website. It seems the chart is inaccurate and misleading.\",\n",
        "    \"I tried canceling my order before it was shipped, but the system wouldn't let me. Now, I’m stuck with something I don’t need.\",\n",
        "    \"The product quality is far below what I expected based on the reviews and description. It feels like I’ve been scammed.\",\n",
        "    \"The live chat feature on the website never connects me to an agent. I’ve tried multiple times, and the automated replies aren’t helpful at all.\",\n",
        "    \"I’ve been charged for a subscription that I never signed up for. It’s unfair, and I haven’t received any explanation or solution yet.\",\n",
        "    \"The instructions for assembling the product were incomplete and confusing. I had to search online to figure out how to put it together.\",\n",
        "    \"My account was locked for no reason, and I wasn’t able to make a purchase. Customer support didn’t resolve this issue quickly.\",\n",
        "    \"The item was marked as 'in stock,' but after I placed the order, I was informed that it’s on backorder and won’t arrive for weeks.\",\n",
        "    \"I received the wrong item in my order, and now I have to go through the hassle of returning it and waiting for a replacement.\",\n",
        "    \"The checkout process on the website is frustratingly slow, and my payment failed multiple times before finally going through.\",\n",
        "    \"My promotional discount code didn’t work at checkout, and I ended up paying the full price. I contacted support but haven’t heard back yet.\",\n",
        "    \"The delivery person left my package outside in the rain, ruining the contents inside. There should be better handling of deliveries.\",\n",
        "    \"I had to pay additional customs fees that weren’t disclosed when I placed the order. This hidden charge is unacceptable.\",\n",
        "    \"The automated phone system doesn’t connect me to a real person, and I’ve been stuck waiting for a resolution for over a week.\",\n",
        "    \"The color of the product I received is completely different from what was shown on the website. It’s not what I ordered at all.\",\n",
        "    \"The mobile app keeps crashing whenever I try to add items to my cart. It’s been impossible to complete my purchase.\",\n",
        "    \"The tracking information for my shipment hasn’t been updated in days, and I have no idea where my package is.\",\n",
        "    \"The item I purchased doesn’t work as advertised. It’s defective and should have been properly tested before being sold.\",\n",
        "    \"I paid for expedited shipping, but my order still arrived late. I feel like I wasted money on a service that wasn’t delivered.\",\n",
        "    \"I’ve been trying to return a product for over two weeks, but the return label hasn’t been sent to me yet. This delay is unacceptable.\"\n",
        "]"
      ],
      "metadata": {
        "id": "Dk1C1Z3eaJUi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 📌 Step 6: Legal Case Summaries\n",
        "\n",
        "The legal dataset provides a **structured collection** of case summaries across multiple practice areas.\n",
        "\n",
        "### *Dataset Structure*:\n",
        "Each case entry contains:\n",
        "- **📄 Summary**: *Detailed case description*\n",
        "- **🏷️ Topic**: *Legal practice area classification*\n",
        "- **🔑 Keywords**: *Relevant legal terminology*\n",
        "\n",
        "### *Practice Areas Covered*:\n",
        "1. *Environmental Law*\n",
        "2. *Privacy Law*\n",
        "3. *Intellectual Property*\n",
        "4. *Antitrust Law*\n",
        "5. *Healthcare Law*\n",
        "---"
      ],
      "metadata": {
        "id": "uZCZzwIRaJIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample legal case summaries dataset\n",
        "legal_summaries = [\n",
        "    {\n",
        "        \"summary\": \"The Supreme Court ruled in favor of the plaintiff regarding environmental regulations, emphasizing the need for stricter enforcement to protect endangered species in industrial zones.\",\n",
        "        \"topic\": \"Environmental Law\",\n",
        "        \"keywords\": [\"Supreme Court\", \"plaintiff\", \"environmental regulations\", \"endangered species\", \"industrial zones\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"A new policy on data privacy was enacted to protect user information, requiring companies to implement stricter encryption standards for all stored data.\",\n",
        "        \"topic\": \"Privacy Law\",\n",
        "        \"keywords\": [\"data privacy\", \"policy\", \"user information\", \"encryption standards\", \"data storage\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"The landmark case addressed intellectual property rights for AI-generated content, establishing that such creations could not yet qualify for traditional copyright protections.\",\n",
        "        \"topic\": \"Intellectual Property\",\n",
        "        \"keywords\": [\"intellectual property\", \"AI\", \"landmark case\", \"copyright\", \"AI-generated content\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"Antitrust concerns were raised in a merger between two major tech companies, with regulators questioning the potential for monopolistic practices in the digital advertising sector.\",\n",
        "        \"topic\": \"Antitrust Law\",\n",
        "        \"keywords\": [\"antitrust\", \"merger\", \"tech companies\", \"monopoly\", \"digital advertising\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"The court dismissed charges of negligence against the pharmaceutical company, citing insufficient evidence to prove a breach of safety protocols during the manufacturing process.\",\n",
        "        \"topic\": \"Healthcare Law\",\n",
        "        \"keywords\": [\"negligence\", \"pharmaceutical company\", \"court dismissal\", \"safety protocols\", \"manufacturing process\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"The court ruled that a major energy company was liable for damages caused by an oil spill that affected coastal communities and wildlife habitats.\",\n",
        "        \"topic\": \"Environmental Law\",\n",
        "        \"keywords\": [\"oil spill\", \"energy company\", \"liability\", \"coastal communities\", \"wildlife habitats\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"A federal ruling mandated that companies must disclose all data breaches affecting more than 10,000 users within 48 hours of detection.\",\n",
        "        \"topic\": \"Privacy Law\",\n",
        "        \"keywords\": [\"data breaches\", \"federal ruling\", \"disclosure\", \"user protection\", \"48-hour rule\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"The court upheld the trademark infringement claim, ruling that the defendant's branding created consumer confusion with an established company's product line.\",\n",
        "        \"topic\": \"Intellectual Property\",\n",
        "        \"keywords\": [\"trademark infringement\", \"branding\", \"consumer confusion\", \"product line\", \"court ruling\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"An antitrust lawsuit was filed against a leading e-commerce platform for allegedly using its market dominance to suppress smaller competitors.\",\n",
        "        \"topic\": \"Antitrust Law\",\n",
        "        \"keywords\": [\"antitrust lawsuit\", \"e-commerce\", \"market dominance\", \"smaller competitors\", \"suppression\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"A healthcare company was fined for failing to comply with federal health data privacy regulations, resulting in unauthorized access to patient records.\",\n",
        "        \"topic\": \"Healthcare Law\",\n",
        "        \"keywords\": [\"healthcare company\", \"fines\", \"data privacy\", \"patient records\", \"non-compliance\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"Environmental advocates sued a chemical manufacturer over illegal waste disposal practices that contaminated local water supplies.\",\n",
        "        \"topic\": \"Environmental Law\",\n",
        "        \"keywords\": [\"illegal waste disposal\", \"chemical manufacturer\", \"water contamination\", \"lawsuit\", \"environmental advocates\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"New legislation on biometric data collection requires businesses to obtain explicit consent before capturing or storing fingerprints or facial recognition data.\",\n",
        "        \"topic\": \"Privacy Law\",\n",
        "        \"keywords\": [\"biometric data\", \"explicit consent\", \"facial recognition\", \"fingerprints\", \"data collection\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"The court ruled that a software developer retained ownership of the source code created during a freelance project, reinforcing independent contractor rights.\",\n",
        "        \"topic\": \"Intellectual Property\",\n",
        "        \"keywords\": [\"source code\", \"software developer\", \"freelance project\", \"ownership\", \"contractor rights\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"Regulators imposed fines on a major telecom company for collusion in price-fixing agreements with its regional partners.\",\n",
        "        \"topic\": \"Antitrust Law\",\n",
        "        \"keywords\": [\"collusion\", \"price-fixing\", \"telecom company\", \"regional partners\", \"regulators\"]\n",
        "    },\n",
        "    {\n",
        "        \"summary\": \"The court held a healthcare provider liable for medical malpractice after failing to diagnose a patient’s life-threatening condition in a timely manner.\",\n",
        "        \"topic\": \"Healthcare Law\",\n",
        "        \"keywords\": [\"medical malpractice\", \"healthcare provider\", \"liability\", \"misdiagnosis\", \"timely care\"]\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "xPxgB8CtaI-F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 📌 Step 7: Vector Generation Process\n",
        "\n",
        "This step implements the **unified embedding generation** for both datasets.\n",
        "\n",
        "### *Processing Pipeline*:\n",
        "1. **Initial Processing**\n",
        "   - *Text extraction*\n",
        "   - *Data validation*\n",
        "   - *Batch preparation*\n",
        "\n",
        "2. **Embedding Generation**\n",
        "   - *Vector creation*\n",
        "   - *Dimension validation*\n",
        "   - *Quality assurance*\n",
        "\n",
        "### *Implementation Details*:\n",
        "- **🔄 Batch Processing**: Optimized for large datasets\n",
        "- **🎯 Accuracy**: Maintains semantic precision\n",
        "- **💾 Storage**: Efficient vector management\n",
        "---"
      ],
      "metadata": {
        "id": "dECi2KWZaIzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for both datasets\n",
        "\n",
        "def generate_embeddings(data_list, is_dict=False):\n",
        "    \"\"\"\n",
        "    Generates embeddings for a list of items.\n",
        "\n",
        "    Args:\n",
        "        data_list (list): List of strings or dictionaries.\n",
        "        is_dict (bool): True if items are dictionaries, False if strings.\n",
        "\n",
        "    Returns:\n",
        "        list: List with added embeddings.\n",
        "    \"\"\"\n",
        "    if is_dict:\n",
        "        # For legal summaries (list of dictionaries)\n",
        "        texts = [item[\"summary\"] for item in data_list]\n",
        "        embeddings = create_embeddings(texts)\n",
        "\n",
        "        # Add embeddings to existing dictionaries\n",
        "        for item, embedding in zip(data_list, embeddings):\n",
        "            item[\"embedding\"] = embedding\n",
        "\n",
        "        return data_list\n",
        "    else:\n",
        "        # For customer complaints (list of strings)\n",
        "        embeddings = create_embeddings(data_list)\n",
        "\n",
        "        # Convert to list of dictionaries\n",
        "        return [{\"text\": text, \"embedding\": emb} for text, emb in zip(data_list, embeddings)]\n",
        "\n",
        "# Apply embedding generation\n",
        "processed_complaints = generate_embeddings(customer_complaints, is_dict=False)\n",
        "processed_legal = generate_embeddings(legal_summaries, is_dict=True)\n"
      ],
      "metadata": {
        "id": "G6-APxjFaIl2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 Step 8: Search Functionality\n",
        "\n",
        "The unified search function implements a **sophisticated retrieval system** combining multiple search capabilities.\n",
        "\n",
        "### *Core Features*:\n",
        "- **🎯 Precision**: Advanced similarity calculations\n",
        "- **🔍 Flexibility**: Multi-dataset search support\n",
        "- **📑 Filtering**: Topic-based result refinement\n",
        "\n",
        "### *Technical Highlights*:\n",
        "1. **Vector Comparison**\n",
        "   - *Cosine similarity metrics*\n",
        "   - *Threshold optimization*\n",
        "2. **Result Ranking**\n",
        "   - *Relevance scoring*\n",
        "   - *Dynamic sorting*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W-4dukQbb3Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Unified Search Function\n",
        "\n",
        "def find_similar_entries(query, dataset, n=3, topic_filter=None):\n",
        "    \"\"\"\n",
        "    Find the n most similar entries in a dataset.\n",
        "\n",
        "    Args:\n",
        "        query (str): Search query.\n",
        "        dataset (list): Dataset of dictionaries with embeddings.\n",
        "        n (int): Number of similar results to return.\n",
        "        topic_filter (str, optional): Topic filter for legal cases.\n",
        "\n",
        "    Returns:\n",
        "        list: List of matching entries sorted by similarity.\n",
        "    \"\"\"\n",
        "    query_embedding = create_embeddings([query])[0]\n",
        "    results = []\n",
        "\n",
        "    for entry in dataset:\n",
        "        # Apply topic filter for legal cases\n",
        "        if topic_filter and topic_filter != \"All\":\n",
        "            if \"topic\" in entry and entry[\"topic\"] != topic_filter:\n",
        "                continue\n",
        "\n",
        "        # Compute similarity\n",
        "        similarity = 1 - distance.cosine(query_embedding, entry[\"embedding\"])\n",
        "        results.append((entry, similarity))\n",
        "\n",
        "    return sorted(results, key=lambda x: x[1], reverse=True)[:n]\n",
        "\n"
      ],
      "metadata": {
        "id": "V56snIi5b3gd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## 📌 **Step 9: User Interface Development**\n",
        "\n",
        "The system implements an **intuitive interface** using Gradio's framework.\n",
        "\n",
        "### *Interface Components*:\n",
        "1. **Input Section**\n",
        "   - *Query text field*\n",
        "   - *Search type selector*\n",
        "   - *Topic filter dropdown*\n",
        "\n",
        "2. **Output Display**\n",
        "   - *Ranked results*\n",
        "   - *Similarity scores*\n",
        "   - *Topic classifications*\n",
        "\n",
        "### *Design Philosophy*:\n",
        "Focuses on **accessibility** while maintaining *powerful functionality* for both technical and non-technical users.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JqaQKoYUb_tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Develop the UI where users can toggle between Customer Complaints and Legal Cases.\n",
        "\n",
        "def unified_search(query, search_type, topic_filter=None):\n",
        "    \"\"\"\n",
        "    Unified search function for both types of content.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user query.\n",
        "        search_type (str): Either \"Customer Complaints\" or \"Legal Cases\".\n",
        "        topic_filter (str, optional): Topic filter for legal cases.\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted search results.\n",
        "    \"\"\"\n",
        "    dataset = processed_complaints if search_type == \"Customer Complaints\" else processed_legal\n",
        "    results = find_similar_entries(query, dataset, topic_filter=topic_filter)\n",
        "\n",
        "    if not results:\n",
        "        return \"No matching entries found.\"\n",
        "\n",
        "    output = f\"🔍 **Search Query:** {query}\\n\\n📂 **Results:**\\n\"\n",
        "    for i, (entry, similarity) in enumerate(results, 1):\n",
        "        output += f\"\\n{i}. **{entry.get('text', '') or entry.get('summary', '')}**\"\n",
        "        if \"topic\" in entry:\n",
        "            output += f\"\\n   📑 **Topic:** {entry['topic']}\"\n",
        "        output += f\"\\n   🎯 **Similarity Score:** {similarity:.2%}\\n\"\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "8SbuRlerb3Gm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📌 Step 11: Launch the Gradio Interface"
      ],
      "metadata": {
        "id": "dFDmugPNb23Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and Launch Gradio Interface\n",
        "\n",
        "unified_interface = gr.Interface(\n",
        "    fn=unified_search,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter Your Query\"),\n",
        "        gr.Radio(\n",
        "            [\"Customer Complaints\", \"Legal Cases\"],\n",
        "            label=\"Select Search Type\",\n",
        "            value=\"Customer Complaints\"\n",
        "        ),\n",
        "        gr.Dropdown(\n",
        "            [\"All\", \"Antitrust Law\", \"Privacy Law\", \"Intellectual Property\",\n",
        "             \"Healthcare Law\", \"Environmental Law\"],\n",
        "            label=\"Filter by Legal Topic (Only for Legal Cases)\",\n",
        "            value=\"All\"\n",
        "        ),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"🔎 Unified Semantic Search\",\n",
        "    description=\"Search across both Customer Complaints and Legal Cases using OpenAI embeddings.\",\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "unified_interface.launch()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "9PFTE3eqb2qG",
        "outputId": "d11ae500-08ad-4300-c8d7-3925c3f5c7fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7a22d2f2221527a95b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7a22d2f2221527a95b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 🚀 System Deployment\n",
        "\n",
        "### *Operation Notes*:\n",
        "- **Runtime Environment**: Google Colab integration\n",
        "- **Resource Management**: Optimized processing\n",
        "- **User Access**: Browser-based interface\n",
        "\n",
        "### *References*:\n",
        "📚 Based on research by Dr. Lee on semantic search applications [Read more](https://drlee.io/building-a-semantic-search-engine-for-customer-complaints-with-openai-a61e9f4f2ba7).  \n",
        "---"
      ],
      "metadata": {
        "id": "kq_KFTBeb2WH"
      }
    }
  ]
}